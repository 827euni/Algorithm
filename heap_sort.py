import heapq

def solve(A, k):
	
	X = [] 
	Y = [] 
	
	for i in A:
		if len(X) == 0 or X[0] <= i:
			heapq.heappush(X,-i) 
			#여기서 들어오는 i는 항상 (-1)을 곱한 형태로 들어오게 하면 가장 큰 값이 음수를 붙였을 떄 가장 작은 값이 되게 된다. 그래서 이후 X의 안에 들어있는 요소가 k를 넘기게 되었을 때 heappop으로 값을 이동시키게 되는데, heappop은 가장 작은 값을 보낼 수 있게 하는 함수임으로, 가장 큰 값을 음수를 곱하여 가장 작은 값으로 만들어 Y로 이동시킬 수 있게 된다.
		else: 
			heapq.heappush(Y,i) 
	
		if len(X) > k: 
			#heap 정렬의 경우에는 완전하고 안정적인 이진트리에서 일어나기 때문에 X와 Y의 배열 안의 요소의 수를 맞춰야 한다. 앞의 연산에서 음수를 곱하여 가장 큰 값을 작은 값으로 만들어 아래의 연산에서 쉽게 최소를 비교할 수 있었다. 하지만, 이것은 원래의 요소가 아니므로 반대편으로 보낼 때는 역시 음수를 붙여 원래의 요소로 만들어주어야 한다. 
			heapq.heappush(Y, -heapq.heappop(X)) 

	return -X[0] #heapq는 최소힙을 제공하는 모델임으로, 음수로 바꿔서 가장 큰 값이 빠지도록 구현했다. 
# 그렇기에 원래값으로 리턴하기 위하여 앞에 음수를 붙여 리턴한다. 

k = int(input())
A = [int(x) for x in input().split()]
heapq.heapify(A) # A is now a min-heap
print(solve(A, k))
#힙정렬은 끊임 없이 자신의 부모노드와 비교하여 상대적으로 작으면 자리를 바꾸기 때문에 최종적인 가장 위의 노드는 필연적으로 가장 작은 값이 되게 하는 알고리즘이다
#그렇기 때문에 항상 부모노드와 자식노드간의 비교를 하게 되고 worst case로 가장 밑에 있는 노드가 가장 작은 노드라고 생각하게 될 때 단계의 개수만큼 수행시간을 가지게 된다. 즉, 하나의 노드가 가지는 수행시간은 밑이 2인 log2의 값을 따른다.
#하지만 이곳의 노드는 가장 작은 값을 찾는 것이 아닌 k번째 작은 값을 찾는 것이므로, k-1만큼 이동시키면 k번째로 작은 요소를 찾을 수 있다. 즉 이 연산에 들어가는 시간 복잡도는 O(klogN) (log함수는 밑이 2인 경우를 상정)이 되므로 총 시간복잡도는 min힙으로 만드는 시간에 힙을 통해 k번째로 작은 수를 찾는 시간을 합해야 하기 때문에 O(N+klogN)이 되게 된다.
#위와 같은 알고리즘은 k가 아무리 크더라도 N만큼 커지지는 않기 때문에 기본적으로 안정적이라는 특징을 가지고 있다. 1번 방법의 경우에는 가장 느린 수행시간을 가지고 있지만, 코드를 짜기 간단하다는 특징이 있다. 제 알고리즘과 비교하여 정확하게 대척점에 있는 코드로, 제가 짠 알고리즘의 경우에는 여기서 가장 짜기 복잡하다는 특징을 가지고 있지만, 앞에서 설명했던것과 같이 안정적이라는 특징을 가지고 있다. 
#2번과 3번 알고리즘의 가장큰 단점은 안정적이지 못하다는 것이다. 기본적으로 평균을 포함하여 최고의 경우에서는 힙 정렬보다 훨씬 빠르게 진행할 수 있다는 특징이 있지만, 최악의 경우를 생각하지 않을 수 없기 때문에 실제로 사용하기는 어려운 코드입니다. MoM의 경우에는 최악의 경우의 시간도 작지만, 실제로는 수행시간이 클 수 있다는 단점을 가지고 있다.
# 즉, 이곳에 있는 모든 알고리즘과 비교하였을 때 힙 정렬은 짜기가 어렵고, 기본적인 평균 수행시간이 퀵정렬과 MoM보다 느리지만, 최악의 경우의 상황을 생각하지 않을 수 없는 현실에서 평균시간과 최악, 또는 최고의 수행시간이 차이가 없다는 점을 들어 가장 안정적으로 사용할 수 있을 것이라 생각됩니다. 